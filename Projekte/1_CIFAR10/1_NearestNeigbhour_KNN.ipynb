{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbour & KNN\n",
    "in diesem Notebook betrachten wir die einfachen Klassifikationsalgorithmen Nearest Neigbour & K-Nearest Neigbour. \n",
    "\n",
    "Vorbedingung ist, dass gelablete Daten vorliegen und eine Klassifzierung gewünscht ist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neigbour NN\n",
    "Am Beispiel von Bild Klassifikation werden hier einfach Test bilder gegen alle Bilder der Trainbild verglichen. \"Vergleich\" bedeutet in diesem Falle, dass die Bilder übereinander gelegt werden, und die Pixelwerte voneinander abgzogen werden. Anschließend kommuliet man jeden Wert zwischen dem einen Testbild und alle Trainbildern zunächst individuell auf, und legt den aufkummulierten Wert in einer List ab. Somit enthält die Liste alle Summen der Differenzen zwischen dem einzelnen Test-Bild und allen Trainbildern. Wir gehen nun davon aus, dass jenes gelablte TrainingsBild, welches die geringste aufkummmuliet Differenz zu dem ungelableten Testimage besitzt, ddem Testbild am ähnlichsten ist. somit labeln wir dem Testimage, das entsprechende Label. Vereinfacht gesprochen werden bei der NN lediglich die beiden Instanzen miteinander verglichen. Für die Distanzmessung wird entweder die Euklidische oder die Manhatten Distanz verwendet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNearest Neigbour KNN\n",
    "KNN ist die Erweiterung zu NN. In diesem Beispiel wird jedoch nicht ausschließlcih der nächste Nachbar, sondern die \"k\"-näcshten Nachbarn für die Zuordnung gewählt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorgehen in diesem Notebook\n",
    "zunächst werden ich die beiden Algorithmen zu NN und KNN selbst implementieren. Anschließend verwende ich die SK-Learn Bibliothek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der Daten, diese wurden bereits im vorherigen Notebook gelden, entapckt, normalisiert & vektorisiert habe\n",
    "train_X = np.load('./DATA/train_X.npy')\n",
    "train_y = np.load('./DATA/train_y.npy')\n",
    "test_X = np.load('./DATA/test_X.npy')\n",
    "test_y = np.load('./DATA/test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000, 10)\n",
      "(10000, 3072)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print((train_X.shape))\n",
    "print((train_y.shape))\n",
    "print((test_X.shape))\n",
    "print((test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_10_CLASSES = [\"Flugz.\",\"PKW\",\"Vogel\",\"Katze\",\"Wild\",\"Hund\", \"Frosch\", \"Pferd\", \"Schiff\",\"LKW\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigene Erstellung des NN-Algorithmus mit Erweiterung zu KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def predictSinglePicture(self, test_X_single, k=1):\n",
    "        distances = []\n",
    "        for i in range(0, len(self.X), 1):\n",
    "            currentDiff = self.X[i] - test_X_single\n",
    "            distances.append(np.argmin(currentDiff))\n",
    "        indexOfPictureWithMindDif = np.argmin(distances)\n",
    "        print(train_y[indexOfPictureWithMindDif])\n",
    "        \n",
    "\n",
    "    def predictTestSet(self, test_X, test_y, train_y):\n",
    "        correctClassified = 0\n",
    "        falesClassified = 0\n",
    "        for i in range(0, len(test_X), 1): #wdh 1000x\n",
    "            realPicture = test_y[i]\n",
    "            distances = []\n",
    "            #for j in range(0, len(self.X),1): # wdh 50000x\n",
    "            for j in range(0, 500,1): # wdh 50000x # for testing smaller set, just the first 500 not 50000 of the train set\n",
    "                currentDiff = self.X[j] - test_X[i]\n",
    "                distances.append(np.argmin(currentDiff))\n",
    "            indexOfPictureWithMindDif = np.argmin(distances)\n",
    "\n",
    "            if(str(train_y[indexOfPictureWithMindDif]) == str(realPicture)):\n",
    "                correctClassified = correctClassified + 1\n",
    "            else:\n",
    "                falesClassified = falesClassified + 1    \n",
    "            if(i % 100 == 0):\n",
    "                print(i)\n",
    "                print(correctClassified)\n",
    "                print(falesClassified)\n",
    "                print(correctClassified/(correctClassified+falesClassified))\n",
    "                print(falesClassified/(correctClassified+falesClassified))\n",
    "                print()\n",
    "        print(\"Final:\")    \n",
    "        print(correctClassified)\n",
    "        print(falesClassified)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NearestNeighbor()\n",
    "NN.train(train_X, train_y)\n",
    "NN.predictTestSet(test_X, test_y, train_y) # correct13 / false87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bsp-Prediction eines einzelnen Wertes\n",
    "im folgenden Block kann mittels der Variable num, ein Bild aus dem Testset gewählt werden. Dieses wird anschließend gegen alle Bilder des Train-Sets verglichen. Jenes bild, welches am wenigsten Differenz, aufweist, wird retour geliefert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BSP-Predicitio für bild \"num\"\n",
    "num = 13\n",
    "NN.predictSinglePicture(test_X[num])\n",
    "print(test_y[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwendung der KNN-Methode von SK-Learn\n",
    "Diese Methode erwartet als Input einen 2-Dimensionalen Vector, daher muss zunächst ein Reshaping stattfinden(was bereits im ersten Notebook stattfand). Die obenstehenden Implementierungen sind insofern \"aufwendig\". mit den folgenden Zeilen konnte ich jedoch gut meine eigene Arbeit gegenprüfen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN -selbsterstellt\n",
    "Knn mit Soft-Voting. Das heist von den nächsten Nachbarn werden zuletzt die Distanzen der gleichen Klassen aufsummiert und durch die anzahl der Klassenteilnehmer geteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y, labels):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.labels = labels\n",
    "        \n",
    "    def predictTestSet(self, test_X, test_y, train_y, k=1):\n",
    "        correctClassified = 0\n",
    "        falesClassified = 0\n",
    "        kNeigbours = []\n",
    "        for i in range(0, len(test_X), 1): #wdh 1000x\n",
    "            realPicture = test_y[i]\n",
    "            distances = []\n",
    "            #for j in range(0, len(self.X),1): # wdh 50000x\n",
    "            for j in range(0, 200,1): # wdh 50000x # for testing smaller set, just the first 500 not 50000 of the train set\n",
    "                currentDiff = self.X[j] - test_X[i]\n",
    "                distances.append([np.argmin(currentDiff), j])\n",
    "\n",
    "            sortedTopK = (sorted(distances, key=lambda s:s[0])[:k+1])\n",
    "            k_Classes = []\n",
    "            checklist1 = [] # prüfung ob wert in der list\n",
    "            checklist2 = []\n",
    "            for k in range(0, len(sortedTopK),1):\n",
    "                searchlist = list(self.y[sortedTopK[k][1]])\n",
    "                categorie = (self.labels[searchlist.index(1)])\n",
    "                dif = (sortedTopK[k][0])\n",
    "                # print(categorie)\n",
    "                # print(sortedTopK[k][1])\n",
    "                if(categorie in checklist1):\n",
    "                    idx = (checklist1.index(categorie))\n",
    "                    checklist2[idx][1] = checklist2[idx][1] + sortedTopK[k][0]\n",
    "                    checklist2[idx][2] = checklist2[idx][2] + 1\n",
    "                else:\n",
    "                    checklist1.append(categorie)\n",
    "                    checklist2.append([categorie, sortedTopK[k][0], 1])\n",
    "            evalList = []\n",
    "            for element in range(0, len(checklist2),1):\n",
    "                evalList.append([checklist2[element][1]/checklist2[element][2], checklist2[element][0]])\n",
    "                \n",
    "            sortEvallist = (sorted(evalList, key=lambda s:s[0])[:k+1])\n",
    "            pred_y = sortEvallist[0][1]\n",
    "            \n",
    "            # Prüfen ob realität oder nicht         \n",
    "            #print(pred_y)\n",
    "            #print(self.labels[list(realPicture).index(1)])\n",
    "            if(pred_y == self.labels[list(realPicture).index(1)]):\n",
    "                correctClassified = correctClassified + 1\n",
    "            else:\n",
    "                falesClassified = falesClassified + 1\n",
    "                \n",
    "        print(correctClassified)\n",
    "        print(falesClassified)\n",
    "        print(correctClassified/(correctClassified+falesClassified))\n",
    "        print(falesClassified/(correctClassified+falesClassified))\n",
    "        print()\n",
    "                                              \n",
    "                                              \n",
    "               \n",
    "                \n",
    "            \n",
    "           \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN = KNearestNeighbor()\n",
    "KNN.train(train_X, train_y, CIFAR_10_CLASSES)\n",
    "#KNN.predictTestSet(test_X, test_y, train_y, 5, CIFAR_10_CLASSES) # correct13 / false87\n",
    "k = 2\n",
    "KNN.predictTestSet(test_X, test_y, train_y, k) # correct13 / false87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN ist ein Spezialfall von KNN\n",
    "wie oben "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2186]\n",
      "[0.2186, 0.1595]\n",
      "[0.2186, 0.1595, 0.1305]\n",
      "[0.2186, 0.1595, 0.1305, 0.0971]\n",
      "[0.2186, 0.1595, 0.1305, 0.0971]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "k_range = [1,3,5,7] # bie k == 1 habe ich NN, alle weiteren sind \n",
    "scores = {}\n",
    "scores_list = []\n",
    "train_X = train_X[:500]\n",
    "train_y = train_y[:500]\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_X, train_y)\n",
    "    pred_y = knn.predict(test_X)\n",
    "    scores[k] = metrics.accuracy_score(test_y,pred_y)\n",
    "    scores_list.append(metrics.accuracy_score(test_y, pred_y))\n",
    "    print(scores_list)\n",
    "print(scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
