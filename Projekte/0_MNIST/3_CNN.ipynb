{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neuronal Network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\1810837475\\.conda\\envs\\testtensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "model = Path(\"./Data/modelcnn.json\")\n",
    "if model.is_file():\n",
    "   # load json and create model\n",
    "    json_file = open('./Data/modelcnn.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(\"./Data/modelcnn.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "else:\n",
    "    modelcnn = Sequential()\n",
    "    modelcnn.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    modelcnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    modelcnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelcnn.add(Dropout(0.25))\n",
    "    modelcnn.add(Flatten())\n",
    "    modelcnn.add(Dense(128, activation='relu'))\n",
    "    modelcnn.add(Dropout(0.5))\n",
    "    modelcnn.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\1810837475\\.conda\\envs\\testtensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.2528 - accuracy: 0.9220 - val_loss: 0.0549 - val_accuracy: 0.9816\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0848 - accuracy: 0.9752 - val_loss: 0.0417 - val_accuracy: 0.9860\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 157s 3ms/step - loss: 0.0642 - accuracy: 0.9805 - val_loss: 0.0355 - val_accuracy: 0.9877\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0539 - accuracy: 0.9835 - val_loss: 0.0282 - val_accuracy: 0.9906\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 0.0291 - val_accuracy: 0.9899\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0404 - accuracy: 0.9879 - val_loss: 0.0273 - val_accuracy: 0.9908\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 0.0286 - val_accuracy: 0.9906\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 168s 3ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0284 - val_accuracy: 0.9904\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0298 - accuracy: 0.9910 - val_loss: 0.0276 - val_accuracy: 0.9910\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 171s 3ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.0260 - val_accuracy: 0.9911\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 170s 3ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.0256 - val_accuracy: 0.9924\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 171s 3ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.0259 - val_accuracy: 0.9920\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'WindowsPath' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-846d65bc5bb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           validation_data=(x_test, y_test))\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'WindowsPath' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "modelcnn.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained Model to disk via JSON\n",
    "model_json = modelcnn.to_json()\n",
    "with open(\"./Data/modelcnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./Data/modelcnn.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
